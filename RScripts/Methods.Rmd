---
title: "LUBDES Bayesian Data Analysis - Methods"
author: "Katharina Gerstner"
date: "Thursday, March 17, 2016"
output: html_document
---

# AIMS  
Synthesize available data to obtain a global perspective on how changes in land use intensity affect both biodiversity (focusing on species richness, because this is what most studies record) and production (measured as biomass per unit area per year, or the nearest available proxy, and their trade-off). 

# METHODS  
## IMPUTATION
We imputed missing data on standard deviations using the bayesian approach of Stevens (2011). This model estimated a population standard deviation $\sigma$. The square of missing sample standard deviations were drawn from a gamma distribution with parametes $\alpha=\frac{n-1}{2}$ and $\beta=\frac{n-1}{2\cdot\overline{\sigma}^2}$.

## META-ANALYSIS
We used a bayesian model approach as it is much better at dealing with multiple sources of uncertainty and can deal with multi-level models. 
We fitted bayesian mixed-effects models and account for (1) non-independence of observations from related sources, i.e. the same study-case, and (2) non-independence from relatedness of LUI comparisons when multiple comparisons within one study-case are used.

# DATA STRUCTURE  
```{r}
df <- data.frame(study=c("A","A","A","A","A","B","B"),case=c(1,1,1,2,2,1,1),LUI.range=c("low-low","low-medium","low-high","low-medium","low-high","low-medium","low-high"), species.group=c(rep("plants",3),rep("mammals",2), rep("plants",2)), Log.RR=rnorm(7),Log.RR.Var=abs(rnorm(7,mean=0,sd=0.5)))
df
```

So we have a hierarchical dependence structure with 3 levels:  
- study  
- study-case  
- study-case-LUI  

# MODEL  
```{r, eval=F}
Log.RR[i] ~ N(mu[i], Log.RR.var[i]+error[i])
mu[i] = X[i,] %*% beta
error[i] = a[i] + v[Study.Case[i]]
```

where $a$ and $v$ are normally distributed around zero with variance $\sigma_a^2 \cdot A$ and $\sigma_v^2 \cdot I$. The matrix $A$ represents the covariance matrix between related study-cases with zeroes on the diagonal. We set the hierarchical covariance to $A_{i,j}=0.5 \cdot \sigma_i \cdot \sigma_j$ if $i, j$ belong to the same study-case and share a control or treatment, because the effect size $i$ determines 50% of the effect size $j$ and vice versa.

We analyzed models of  
1. Grand mean  
2. LUI ranges  
3. LUI ranges and interactions with species group, product, biome and performed variable selection using the deviance information criterion DIC which is comparable with AIC but suitable for hierarchical models where the number of parameters is not so clearly defined (Gelman & Hill 2006, p. 525f).

# CONVERGENCE
We visually checked for convergence of Markov Chains using trace plots. 

# GOODNESS-OF-FIT  
Residual Plot
```{r, eval=F}
residuals.mean <- samps.statistics[grep("residuals",rownames(samps.statistics)),"Mean"]
predictions.mean <- samps.statistics[grep("predictions",rownames(samps.statistics)),"Mean"]
plot(residuals.mean~predictions.mean, main=paste(model.name)) # should look like the sky at night
```

Bayesian p-value 
```{r, eval=F}
for(i in 1:N.obs){
  residuals[i] <- Log.RR[i]-mu[i] # Residuals for observed data
  predictions[i] <- mu[i] # Predicted values
  sq.res[i] <- pow(residuals[i],2) # Squared residuals for observed data
  Log.RR.tau[i] <- pow(Log.RR.Var[i],-2)
  Log.RR.new[i] ~ dnorm(mu[i],Log.RR.tau[i]) # one new data set at each MCMC iteration
  sq.res.new[i] <- pow(Log.RR.new[i]-predictions[i],2) # Squared residuals for new data
}    
SSR <- sum(sq.res) # Sum of squared residuals for actual data set
SSR.new <- sum(sq.res.new) # Sum of squared residuals for new data set
test <- step(SSR-SSR.new) # Test whether new data set more extreme, step() tests for x â‰¥ 0
bpvalue <- mean(test) # Bayesian p-value
```

# HETEROGENEITY
```{r, eval=F}
Q_T <- t(Log.RR.tau^2)*sq.res # cf. Koricheva et al., p111
I.sq <- max(c(100*(Q_T-(N.obs-1))/Q_T,0)) #  This metric quantifies the heterogeneity by comparing Q_T to its expected value under the assumption of homogeneity and can be interpreted as the percentage of total heterogeneity that can be attributed to between-study variance.
``` 

# PUBLICATION BIAS




